import logging
import aiohttp
import asyncio
import re
from urllib.parse import quote

from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.client.default import DefaultBotProperties
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton

API_TOKEN = "8171207811:AAGPMC93yKCM_KOmzJ5cr0WxgLJs3ycO5MQ"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

bot = Bot(token=API_TOKEN, default=DefaultBotProperties(parse_mode="HTML"))
dp = Dispatcher()

# --- –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é ---
main_menu = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton(text="üîé –ü–æ–∏—Å–∫")],
        [KeyboardButton(text="‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ")]
    ],
    resize_keyboard=True
)

# --- –ö–Ω–æ–ø–∫–∞ "–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é" ---
back_to_menu = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton(text="üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é")]
    ],
    resize_keyboard=True
)

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ ---
def analyze_complex_query(text: str) -> dict:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –ø–æ–∏—Å–∫–∞
    """
    text_lower = text.lower()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
    query_type = "general"
    search_terms = []
    
    # –ü–æ–∏—Å–∫ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –¥–≤—É–º—è –ø–æ–Ω—è—Ç–∏—è–º–∏
    difference_patterns = [
        r'—Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É (.+) –∏ (.+)',
        r'—á–µ–º –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è (.+) –æ—Ç (.+)',
        r'–æ—Ç–ª–∏—á–∏–µ (.+) –æ—Ç (.+)',
        r'—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (.+) –∏ (.+)',
        r'(.+) vs (.+)',
        r'(.+) –∏–ª–∏ (.+)'
    ]
    
    for pattern in difference_patterns:
        match = re.search(pattern, text_lower)
        if match:
            query_type = "difference"
            search_terms = [match.group(1).strip(), match.group(2).strip()]
            break
    
    # –ü–æ–∏—Å–∫ –∏—Å—Ç–æ—Ä–∏–∏
    history_patterns = [
        r'–∏—Å—Ç–æ—Ä–∏—è (.+)',
        r'–∫–æ–≥–¥–∞ –ø–æ—è–≤–∏–ª(—Å—è|–∞—Å—å|–æ—Å—å) (.+)',
        r'–æ—Å–Ω–æ–≤–∞–Ω–∏(–µ|—è) (.+)',
        r'—Å–æ–∑–¥–∞–Ω–∏(–µ|—è) (.+)'
    ]
    
    if not search_terms:
        for pattern in history_patterns:
            match = re.search(pattern, text_lower)
            if match:
                query_type = "history"
                search_terms = [match.group(1).strip()]
                break
    
    # –ü–æ–∏—Å–∫ —Ñ–∞–∫—Ç–æ–≤/–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    if not search_terms:
        query_type = "general"
        search_terms = [text.strip()]
    
    return {
        "type": query_type,
        "terms": search_terms,
        "original": text
    }

async def fetch_difference_info(term1: str, term2: str) -> str:
    """
    –ò—â–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –¥–≤—É–º—è –ø–æ–Ω—è—Ç–∏—è–º–∏
    """
    headers = {
        "User-Agent": "BrandHelperBot/1.0",
        "Accept": "application/json"
    }
    
    async with aiohttp.ClientSession(headers=headers) as session:
        # –ò—â–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –æ–±–æ–∏–º —Ç–µ—Ä–º–∏–Ω–∞–º
        info1 = await fetch_single_term_info(term1, session)
        info2 = await fetch_single_term_info(term2, session)
        
        if not info1 and not info2:
            return f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∏ –æ '{term1}', –Ω–∏ –æ '{term2}'"
        
        result = f"<b>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ: {term1} vs {term2}</b>\n\n"
        
        if info1:
            result += f"<b>{term1}:</b>\n{info1}\n\n"
        else:
            result += f"<b>{term1}:</b>\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\n\n"
            
        if info2:
            result += f"<b>{term2}:</b>\n{info2}\n\n"
        else:
            result += f"<b>{term2}:</b>\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –æ–±–æ–∏–º
        if info1 and info2:
            result += "üîç <b>–ö–ª—é—á–µ–≤—ã–µ —Ä–∞–∑–ª–∏—á–∏—è:</b>\n"
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–∞–∑–ª–∏—á–∏–π
            result += "‚Ä¢ –≠—Ç–æ —Ä–∞–∑–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è/–æ–±—ä–µ–∫—Ç—ã/—è–≤–ª–µ–Ω–∏—è\n"
            result += "‚Ä¢ –ò–º–µ—é—Ç —Ä–∞–∑–ª–∏—á–Ω–æ–µ –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ\n"
            result += "‚Ä¢ –û—Ç–ª–∏—á–∞—é—Ç—Å—è –ø–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º –∏ —Å–≤–æ–π—Å—Ç–≤–∞–º\n"
        
        return result

async def fetch_single_term_info(term: str, session: aiohttp.ClientSession) -> str:
    """
    –ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–¥–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–µ
    """
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä—É—Å—Å–∫—É—é –í–∏–∫–∏–ø–µ–¥–∏—é
        search_url = "https://ru.wikipedia.org/w/api.php"
        params = {"action": "query", "list": "search", "srsearch": term, "format": "json"}
        async with session.get(search_url, params=params) as resp:
            if resp.status == 200:
                data = await resp.json()
                search_results = data.get("query", {}).get("search", [])
                if search_results:
                    page_title = search_results[0]["title"]
                    qtitle = quote(page_title, safe='')
                    summary_url = f"https://ru.wikipedia.org/api/rest_v1/page/summary/{qtitle}"
                    async with session.get(summary_url) as sresp:
                        if sresp.status == 200:
                            sdata = await sresp.json()
                            extract = sdata.get("extract")
                            if extract:
                                clean_text = re.sub(r"\s*\(.*?\)", "", extract)
                                clean_text = re.sub(r"\[\d+\]", "", clean_text)
                                sentences = clean_text.split(". ")
                                short_text = ". ".join(sentences[:3]) + "."
                                return short_text
    except Exception:
        logger.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ {term}")
    
    return ""

async def fetch_history_info(term: str) -> str:
    """
    –ò—â–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ—Ä–º–∏–Ω–µ
    """
    headers = {
        "User-Agent": "BrandHelperBot/1.0",
        "Accept": "application/json"
    }
    
    async with aiohttp.ClientSession(headers=headers) as session:
        try:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∏—Å—Ç–æ—Ä–∏—é
            search_query = f"–∏—Å—Ç–æ—Ä–∏—è {term}"
            search_url = "https://ru.wikipedia.org/w/api.php"
            params = {"action": "query", "list": "search", "srsearch": search_query, "format": "json"}
            async with session.get(search_url, params=params) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    search_results = data.get("query", {}).get("search", [])
                    if search_results:
                        page_title = search_results[0]["title"]
                        qtitle = quote(page_title, safe='')
                        summary_url = f"https://ru.wikipedia.org/api/rest_v1/page/summary/{qtitle}"
                        async with session.get(summary_url) as sresp:
                            if sresp.status == 200:
                                sdata = await sresp.json()
                                extract = sdata.get("extract")
                                url = sdata.get("content_urls", {}).get("desktop", {}).get("page", "")
                                if extract:
                                    # –ò—â–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∫—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ
                                    history_keywords = ['–æ—Å–Ω–æ–≤–∞–Ω', '—Å–æ–∑–¥–∞–Ω', '–ø–æ—è–≤–∏–ª—Å—è', '–∏—Å—Ç–æ—Ä–∏—è', '–≥–æ–¥', '–≤–µ–∫']
                                    sentences = extract.split(". ")
                                    history_sentences = []
                                    
                                    for sentence in sentences:
                                        if any(keyword in sentence.lower() for keyword in history_keywords):
                                            history_sentences.append(sentence)
                                    
                                    if history_sentences:
                                        result = ". ".join(history_sentences[:5]) + "."
                                        clean_result = re.sub(r"\s*\(.*?\)", "", result)
                                        clean_result = re.sub(r"\[\d+\]", "", clean_result)
                                        return f"<b>–ò—Å—Ç–æ—Ä–∏—è: {term}</b>\n\n{clean_result}\n\nüîó <a href='{url}'>–ü–æ–¥—Ä–æ–±–Ω–µ–µ</a>"
        except Exception:
            logger.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏—Å—Ç–æ—Ä–∏–∏ {term}")
    
    return f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ '{term}'"

@dp.message(Command("start"))
async def start_handler(message: types.Message):
    await message.answer("üëã –ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –≥–ª–∞–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ –ø–æ–∏—Å–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ 0w0. –í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=main_menu)

@dp.message(F.text == "üîé –ü–æ–∏—Å–∫")
async def search_start(message: types.Message):
    await message.answer("–ù–∞–ø–∏—à–∏—Ç–µ —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å, –∏ —è –Ω–∞–π–¥—É —Å–∞–º—É—é –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é!\n\n–ù–∞–ø—Ä–∏–º–µ—Ä:\n‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É iPhone –∏ Android\n‚Ä¢ –ò—Å—Ç–æ—Ä–∏—è Microsoft\n‚Ä¢ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Python –∏ Java\n‚Ä¢ –ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
                         reply_markup=back_to_menu)

@dp.message(F.text == "‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ")
async def project_info(message: types.Message):
    text = (
        "‚ú® <b>Brend AI</b> ‚ú®\n\n"
        "–ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–∂–µ—Ç –≤–∞–º —É–∑–Ω–∞—Ç—å –≤—Å—é –≤–∞–∂–Ω—É—é –∏ –Ω—É–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.\n"
        "üìñ –í—ã —É–∑–Ω–∞–µ—Ç–µ –∏—Å—Ç–æ—Ä–∏—é, –≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏ –æ—Ç–ª–∏—á–∏—è –º–µ–∂–¥—É –≤–µ—â–∞–º–∏.\n"
        "üß† –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å —á—Ç–æ-—Ç–æ –Ω–æ–≤–æ–µ –∏ –ø–æ–ª–µ–∑–Ω–æ–µ ‚Äî –≤–∞–º —Å—é–¥–∞!\n"
        "(–ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω Fram1se)"
    )
    await message.answer(text, reply_markup=back_to_menu)

@dp.message(F.text == "üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é")
async def return_to_menu(message: types.Message):
    await message.answer("üëã –í—ã —Å–Ω–æ–≤–∞ –≤ –≥–ª–∞–≤–Ω–æ–º –º–µ–Ω—é!", reply_markup=main_menu)

@dp.message(F.text)
async def brand_handler(message: types.Message):
    user_text = message.text.strip()

    # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª—É–∂–µ–±–Ω–∞—è –∫–Ω–æ–ø–∫–∞
    if user_text == "üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é":
        await message.answer("üëã –í—ã —Å–Ω–æ–≤–∞ –≤ –≥–ª–∞–≤–Ω–æ–º –º–µ–Ω—é!", reply_markup=main_menu)
        return

    status_msg = await message.answer(f"üîé –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–ø—Ä–æ—Å...")

    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        analyzed = analyze_complex_query(user_text)
        
        if analyzed["type"] == "difference" and len(analyzed["terms"]) == 2:
            await status_msg.edit_text(f"üîç –°—Ä–∞–≤–Ω–∏–≤–∞—é '{analyzed['terms'][0]}' –∏ '{analyzed['terms'][1]}'...")
            result = await fetch_difference_info(analyzed['terms'][0], analyzed['terms'][1])
        
        elif analyzed["type"] == "history":
            await status_msg.edit_text(f"üìö –ò—â—É –∏—Å—Ç–æ—Ä–∏—é '{analyzed['terms'][0]}'...")
            result = await fetch_history_info(analyzed['terms'][0])
        
        else:
            await status_msg.edit_text(f"üîé –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ '{user_text}'...")
            result = await fetch_brand_info(user_text)

        if result:
            await status_msg.edit_text(result)
            await message.answer("–•–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å —á—Ç–æ-—Ç–æ –µ—â—ë?", reply_markup=back_to_menu)
        else:
            await status_msg.edit_text("üòî –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à—ë–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.")
            await message.answer("–•–æ—Ç–∏—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å?", reply_markup=back_to_menu)

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞:")
        await status_msg.edit_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.")
        await message.answer("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.", reply_markup=back_to_menu)

# --- –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ (–æ—Å—Ç–∞–≤—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
async def fetch_brand_info(brand: str) -> str:
    headers = {
        "User-Agent": "BrandHelperBot/1.0 (https://t.me/YourBotUsername)",
        "Accept": "application/json"
    }
    timeout = aiohttp.ClientTimeout(total=5)

    async with aiohttp.ClientSession(timeout=timeout, headers=headers) as session:
        # --- –†—É—Å—Å–∫–∞—è –í–∏–∫–∏–ø–µ–¥–∏—è ---
        try:
            search_url = "https://ru.wikipedia.org/w/api.php"
            params = {"action": "query", "list": "search", "srsearch": brand, "format": "json"}
            async with session.get(search_url, params=params) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    search_results = data.get("query", {}).get("search", [])
                    if search_results:
                        page_title = search_results[0]["title"]
                        qtitle = quote(page_title, safe='')
                        summary_url = f"https://ru.wikipedia.org/api/rest_v1/page/summary/{qtitle}"
                        async with session.get(summary_url) as sresp:
                            if sresp.status == 200:
                                sdata = await sresp.json()
                                extract = sdata.get("extract")
                                url = sdata.get("content_urls", {}).get("desktop", {}).get("page", "")
                                if extract:
                                    return clean_summary(page_title, extract, url)
        except Exception:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ —Ä—É—Å—Å–∫–æ–π –í–∏–∫–∏–ø–µ–¥–∏–∏:")

        # --- –ê–Ω–≥–ª–∏–π—Å–∫–∞—è –í–∏–∫–∏–ø–µ–¥–∏—è ---
        try:
            search_url_en = "https://en.wikipedia.org/w/api.php"
            params = {"action": "query", "list": "search", "srsearch": brand, "format": "json"}
            async with session.get(search_url_en, params=params) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    search_results = data.get("query", {}).get("search", [])
                    if search_results:
                        page_title = search_results[0]["title"]
                        qtitle = quote(page_title, safe='')
                        summary_url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{qtitle}"
                        async with session.get(summary_url) as sresp:
                            if sresp.status == 200:
                                sdata = await sresp.json()
                                extract = sdata.get("extract")
                                url = sdata.get("content_urls", {}).get("desktop", {}).get("page", "")
                                if extract:
                                    return clean_summary(page_title, extract, url)
        except Exception:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –∞–Ω–≥–ª–∏–π—Å–∫–æ–π –í–∏–∫–∏–ø–µ–¥–∏–∏:")

        # --- DuckDuckGo ---
        try:
            ddg_url = f"https://api.duckduckgo.com/?q={quote(brand)}&format=json&lang=ru"
            async with session.get(ddg_url) as resp:
                if resp.status == 200:
                    dd = await resp.json()
                    text = dd.get("AbstractText") or (dd.get("RelatedTopics") and dd["RelatedTopics"][0].get("Text"))
                    if text:
                        short = re.sub(r"\s*\(.*?\)", "", text)
                        short = re.sub(r"\[\d+\]", "", short)
                        short_sent = ". ".join(short.split(". ")[:6]) + "."
                        if len(short_sent) > 900:
                            short_sent = short_sent[:900].rsplit(".", 1)[0] + "."
                        return f"<b>{brand}</b>\n\n{short_sent}\n\nüîó DuckDuckGo"
        except Exception:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ DuckDuckGo")

    return ""

def clean_summary(title: str, text: str, url: str) -> str:
    clean_text = re.sub(r"\s*\(.*?\)", "", text)
    clean_text = re.sub(r"\[\d+\]", "", clean_text)
    sentences = clean_text.split(". ")
    short_text = ". ".join(sentences[:6]) + "."
    if len(short_text) > 900:
        short_text = short_text[:900].rsplit(".", 1)[0] + "."
    return f"<b>{title}</b>\n\n{short_text}\n\nüîó <a href='{url}'>–ü–æ–¥—Ä–æ–±–Ω–µ–µ</a>"

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())